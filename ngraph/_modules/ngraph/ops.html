

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ngraph.ops &mdash; Documentation for the nGraph Library and Compiler Stack</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  
  
<!-- <link href="https://fonts.googleapis.com/css?family=Nunito:300,300i,400&display=swap&subset=latin-ext" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Nunito+Sans:300,400,600,700,800,900" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="Documentation for the nGraph Library and Compiler Stack" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>


<body> 
  <div id="menu-float" class="menu-float">
    <a href="https://www.ngraph.ai" target="_blank"><i class="fa fa-home"></i></a>
    <a href="https://ngraph.nervanasys.com/docs/latest" title="Documentation Home"><i class="fa fa-book"></i></a>
    <a href="https://www.ngraph.ai/tutorials" title="Tutorials"><i class="fa fa-user-circle"></i></a>
    <a href="https://www.youtube.com/embed/C9S0nmNS8bQ" target="_blank"><i class="fa fa-video-camera"></i></a>
    <a href="https://ngraph.slack.com/" title="nGraph Slack Channel"><i class="fa fa-slack"></i></a>
    <a href="https://github.com/NervanaSystems/ngraph/blob/master/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
    <a href="https://www.github.com/NervanaSystems/ngraph"><img src="https://travis-ci.org/NervanaSystems/ngraph.svg?branch=master"></a></div></body>


<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html">
          

          
            
            <br/><img src="../../_static/logo.png" class="logo" />
	    nGraph Compiler Stack
          
          </a>

          
            
            
              <div class="version">
                0.29
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search nGraph Documentation" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

    <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="docvs">nGraph Compiler stack</span>
      v: 0.29
      <span></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Recent Versions<i class="fa fa-terminal"></i></dt>
        <dd><!-- Until our https://docs.ngraph.ai/ publishing is set up, we link to GitHub -->  
          <ul>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.27.1-rc.1">0.27.1</a></li> 
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.27.0-rc.1">0.27.0</a></li> 
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.26.0">0.26.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.25.1-rc.10">0.25.1</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.25.0">0.25.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.24.0">0.24.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.22.2-rc.0">0.22.2</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.22.1">0.22.1</a></li>
         </ul></dd>
      </dl>
      <dl>
        <dt>Links</dt>
          <dd>
           <a href="https://www.ngraph.ai/">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/NervanaSystems/ngraph/releases">All Releases</a>
          </dd>
      </dl>
    </div>
</div>


        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
            <span class="toctree-expand"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
</ul>
<p class="caption"><span class="caption-text">Framework Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/overview.html">Basic concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/tensorflow_connect.html">TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/onnx_integ.html">ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/paddle_integ.html">PaddlePaddle*</a></li>
</ul>
<p class="caption"><span class="caption-text">nGraph Core</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../core/overview.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../buildlb.html">Build and Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/constructing-graphs/index.html">Constructing Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/passes/passes.html">Compiler Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/fusion/index.html">Pattern Matcher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ops/index.html">nGraph Core Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../provenance/index.html">Provenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dynamic/index.html">Dynamic Shapes</a></li>
</ul>
<p class="caption"><span class="caption-text">Backend Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../backends/index.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends/cpp-api.html">Adding New Backends</a></li>
</ul>
<p class="caption"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/qat.html">Quantization-Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Validated Workloads</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/validated/list.html">Validated Workloads</a></li>
</ul>
<p class="caption"><span class="caption-text">Diagnostics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_core.html">Diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_tf.html">Debug TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_onnx.html">Debug ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_paddle.html">Debug PaddlePaddle*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/viz_tools.html">General Visualization Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/profiling.html">Performance testing with <code class="docutils literal notranslate"><span class="pre">nbench</span></code></a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../project/contribution-guide.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
</span>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">nGraph Compiler Stack</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
        <li><a href="../index.html">Module code</a> &raquo;</li>
      
    <li>ngraph.ops</li>
    <li class="wy-breadcrumbs-aside">
      
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for ngraph.ops</h1><div class="highlight"><pre>
<span></span><span class="c1"># ******************************************************************************</span>
<span class="c1"># Copyright 2017-2020 Intel Corporation</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ******************************************************************************</span>

<span class="sd">&quot;&quot;&quot;Factory functions for all ngraph ops.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">ngraph.impl</span> <span class="k">import</span> <span class="n">AxisSet</span><span class="p">,</span> <span class="n">AxisVector</span><span class="p">,</span> <span class="n">Coordinate</span><span class="p">,</span> <span class="n">CoordinateDiff</span><span class="p">,</span> <span class="n">Function</span><span class="p">,</span> <span class="n">Node</span><span class="p">,</span> \
    <span class="n">Shape</span><span class="p">,</span> <span class="n">Strides</span>

<span class="kn">from</span> <span class="nn">ngraph.impl.op</span> <span class="k">import</span> <span class="n">Abs</span><span class="p">,</span> <span class="n">Acos</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span> <span class="n">And</span><span class="p">,</span> <span class="n">Asin</span><span class="p">,</span> <span class="n">ArgMax</span><span class="p">,</span> <span class="n">ArgMin</span><span class="p">,</span> <span class="n">Atan</span><span class="p">,</span> <span class="n">AvgPool</span><span class="p">,</span> \
    <span class="n">BatchNormTraining</span><span class="p">,</span> <span class="n">BatchNormInference</span><span class="p">,</span> <span class="n">Broadcast</span><span class="p">,</span> <span class="n">Ceiling</span><span class="p">,</span> <span class="n">Clamp</span><span class="p">,</span> <span class="n">Concat</span><span class="p">,</span> <span class="n">Constant</span><span class="p">,</span> <span class="n">Convert</span><span class="p">,</span> \
    <span class="n">Convolution</span><span class="p">,</span> <span class="n">ConvolutionBackpropData</span><span class="p">,</span> <span class="n">Cos</span><span class="p">,</span> <span class="n">Cosh</span><span class="p">,</span> <span class="n">DepthToSpace</span><span class="p">,</span> <span class="n">Dequantize</span><span class="p">,</span> <span class="n">Divide</span><span class="p">,</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Elu</span><span class="p">,</span> \
    <span class="n">FakeQuantize</span><span class="p">,</span> <span class="n">Equal</span><span class="p">,</span> <span class="n">Exp</span><span class="p">,</span> <span class="n">Floor</span><span class="p">,</span> <span class="n">Gelu</span><span class="p">,</span> <span class="n">Gemm</span><span class="p">,</span> <span class="n">GetOutputElement</span><span class="p">,</span> <span class="n">Greater</span><span class="p">,</span> <span class="n">GreaterEq</span><span class="p">,</span> <span class="n">GRN</span><span class="p">,</span> \
    <span class="n">GroupConvolution</span><span class="p">,</span> <span class="n">HardSigmoid</span><span class="p">,</span> <span class="n">Less</span><span class="p">,</span> <span class="n">LessEq</span><span class="p">,</span> <span class="n">Log</span><span class="p">,</span> <span class="n">LRN</span><span class="p">,</span> <span class="n">Max</span><span class="p">,</span> <span class="n">Maximum</span><span class="p">,</span> <span class="n">MaxPool</span><span class="p">,</span> <span class="n">Min</span><span class="p">,</span> <span class="n">Minimum</span><span class="p">,</span> \
    <span class="n">Multiply</span><span class="p">,</span> <span class="n">MVN</span><span class="p">,</span> <span class="n">Negative</span><span class="p">,</span> <span class="n">Not</span><span class="p">,</span> <span class="n">NotEqual</span><span class="p">,</span> <span class="n">OneHot</span><span class="p">,</span> <span class="n">Or</span><span class="p">,</span> <span class="n">Pad</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Product</span><span class="p">,</span> <span class="n">Power</span><span class="p">,</span> \
    <span class="n">Quantize</span><span class="p">,</span> <span class="n">QuantizedConvolution</span><span class="p">,</span> <span class="n">QuantizedDot</span><span class="p">,</span> <span class="n">PRelu</span><span class="p">,</span> <span class="n">Relu</span><span class="p">,</span> <span class="n">RNNCell</span><span class="p">,</span> <span class="n">ReplaceSlice</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> \
    <span class="n">Reverse</span><span class="p">,</span> <span class="n">ScaleShift</span><span class="p">,</span> <span class="n">Select</span><span class="p">,</span> <span class="n">ShuffleChannels</span><span class="p">,</span> <span class="n">Sign</span><span class="p">,</span> <span class="n">Sin</span><span class="p">,</span> <span class="n">Sinh</span><span class="p">,</span> <span class="n">Slice</span><span class="p">,</span> <span class="n">Softmax</span><span class="p">,</span> <span class="n">SpaceToDepth</span><span class="p">,</span> \
    <span class="n">Sqrt</span><span class="p">,</span> <span class="n">SquaredDifference</span><span class="p">,</span> <span class="n">Squeeze</span><span class="p">,</span> <span class="n">Subtract</span><span class="p">,</span> <span class="n">Sum</span><span class="p">,</span> <span class="n">Tan</span><span class="p">,</span> <span class="n">Tanh</span><span class="p">,</span> <span class="n">TopK</span><span class="p">,</span> <span class="n">Unsqueeze</span>


<span class="kn">from</span> <span class="nn">typing</span> <span class="k">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">ngraph.utils.broadcasting</span> <span class="k">import</span> <span class="n">get_broadcast_axes</span>
<span class="kn">from</span> <span class="nn">ngraph.utils.decorators</span> <span class="k">import</span> <span class="n">nameable_op</span><span class="p">,</span> <span class="n">binary_op</span><span class="p">,</span> <span class="n">unary_op</span>
<span class="kn">from</span> <span class="nn">ngraph.utils.input_validation</span> <span class="k">import</span> <span class="n">assert_list_of_ints</span>
<span class="kn">from</span> <span class="nn">ngraph.utils.reduction</span> <span class="k">import</span> <span class="n">get_reduction_axes</span>
<span class="kn">from</span> <span class="nn">ngraph.utils.types</span> <span class="k">import</span> <span class="n">NumericType</span><span class="p">,</span> <span class="n">NumericData</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">,</span> <span class="n">make_constant_node</span><span class="p">,</span> \
    <span class="n">NodeInput</span><span class="p">,</span> <span class="n">ScalarData</span><span class="p">,</span> <span class="n">as_node</span>
<span class="kn">from</span> <span class="nn">ngraph.utils.types</span> <span class="k">import</span> <span class="n">get_element_type</span>


<div class="viewcode-block" id="parameter"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.parameter">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">parameter</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (TensorShape, NumericType, str) -&gt; Parameter</span>
    <span class="sd">&quot;&quot;&quot;Return an ngraph Parameter object.&quot;&quot;&quot;</span>
    <span class="n">assert_list_of_ints</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;Parameter shape must be a list of integer values.&#39;</span><span class="p">)</span>
    <span class="n">element_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">element_type</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="constant"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.constant">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">constant</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NumericData, NumericType, str) -&gt; Constant</span>
    <span class="sd">&quot;&quot;&quot;Create a Constant node from provided value.</span>

<span class="sd">    :param value: One of: array of values or scalar to initialize node with.</span>
<span class="sd">    :param dtype: The data type of provided data.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    :return: The Constant node initialized with provided data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">make_constant_node</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="elu"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.elu">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">elu</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NumericType, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform Exponential Linear Unit operation element-wise on data from input node.</span>

<span class="sd">    Computes exponential linear: alpha * (exp(data) - 1) if &lt; 0, data otherwise.</span>

<span class="sd">    For more information refer to:</span>
<span class="sd">    `Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</span>
<span class="sd">    &lt;http://arxiv.org/abs/1511.07289&gt;`_</span>

<span class="sd">    :param data: Input tensor. One of: input node, array or scalar.</span>
<span class="sd">    :param alpha: Scalar multiplier for negative values.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing an ELU operation on its input data element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Elu</span><span class="p">(</span><span class="n">as_node</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">alpha</span><span class="p">)</span></div>


<div class="viewcode-block" id="shuffle_channels"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.shuffle_channels">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">shuffle_channels</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, int, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform permutation on data in the channel dimension of the input tensor.</span>

<span class="sd">    The operation is the equivalent with the following transformation of the input tensor</span>
<span class="sd">    :code:`data` of shape [N, C, H, W]:</span>

<span class="sd">    :code:`data_reshaped` = reshape(:code:`data`, [N, group, C / group, H * W])</span>

<span class="sd">    :code:`data_trnasposed` = transpose(:code:`data_reshaped`, [0, 2, 1, 3])</span>

<span class="sd">    :code:`output` = reshape(:code:`data_trnasposed`, [N, C, H, W])</span>

<span class="sd">    For example:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        Inputs: tensor of shape [1, 6, 2, 2]</span>

<span class="sd">                data = [[[[ 0.,  1.], [ 2.,  3.]],</span>
<span class="sd">                         [[ 4.,  5.], [ 6.,  7.]],</span>
<span class="sd">                         [[ 8.,  9.], [10., 11.]],</span>
<span class="sd">                         [[12., 13.], [14., 15.]],</span>
<span class="sd">                         [[16., 17.], [18., 19.]],</span>
<span class="sd">                         [[20., 21.], [22., 23.]]]]</span>

<span class="sd">                axis = 1</span>
<span class="sd">                groups = 3</span>

<span class="sd">        Output: tensor of shape [1, 6, 2, 2]</span>

<span class="sd">                output = [[[[ 0.,  1.], [ 2.,  3.]],</span>
<span class="sd">                           [[ 8.,  9.], [10., 11.]],</span>
<span class="sd">                           [[16., 17.], [18., 19.]],</span>
<span class="sd">                           [[ 4.,  5.], [ 6.,  7.]],</span>
<span class="sd">                           [[12., 13.], [14., 15.]],</span>
<span class="sd">                           [[20., 21.], [22., 23.]]]]</span>

<span class="sd">    :param data: The node with input tensor.</span>
<span class="sd">    :param axis: Channel dimension index in the data tensor.</span>
<span class="sd">                 A negative value means that the index should be calculated</span>
<span class="sd">                 from the back of the input data shape.</span>
<span class="sd">    :param group:The channel dimension specified by the axis parameter</span>
<span class="sd">                 should be split into this number of groups.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a permutation on data in the channel dimension</span>
<span class="sd">             of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ShuffleChannels</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span></div>


<div class="viewcode-block" id="squeeze"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.squeeze">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform squeeze operation on input tensor.</span>

<span class="sd">    Remove single-dimensional entries from the shape of a tensor.</span>
<span class="sd">    Takes a parameter :code:`axes` with a list of axes to squeeze.</span>
<span class="sd">    If :code:`axes` is not provided, all the single dimensions will be removed from the shape.</span>
<span class="sd">    If an :code:`axis` is selected with shape entry not equal to one, an error is raised.</span>


<span class="sd">    For example:</span>

<span class="sd">       Inputs: tensor with shape [1, 2, 1, 3, 1, 1], axes=[2, 4]</span>

<span class="sd">       Result: tensor with shape [1, 2, 3, 1]</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param axes: List of non-negative integers, indicate the dimensions to squeeze.</span>
<span class="sd">                  One of: input node or array.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: The new node performing a squeeze operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Squeeze</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">as_node</span><span class="p">(</span><span class="n">axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="unsqueeze"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.unsqueeze">[docs]</a><span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform unsqueeze operation on input tensor.</span>

<span class="sd">    Insert single-dimensional entries to the shape of a tensor. Takes one required argument axes,</span>
<span class="sd">    a list of dimensions that will be inserted.</span>
<span class="sd">    Dimension indices in axes are as seen in the output tensor.</span>

<span class="sd">    For example: Inputs: tensor with shape [3, 4, 5], axes=[0, 4]</span>
<span class="sd">                 Result: tensor with shape [1, 3, 4, 5, 1]</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param axes: List of non-negative integers, indicate the dimensions to be inserted.</span>
<span class="sd">                  One of: input node or array.</span>
<span class="sd">    :return: The new node performing an unsqueeze operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Unsqueeze</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">as_node</span><span class="p">(</span><span class="n">axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="grn"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.grn">[docs]</a><span class="k">def</span> <span class="nf">grn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, float, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform Global Response Normalization with L2 norm (across channels only).</span>

<span class="sd">    Computes GRN operation on channels for input tensor:</span>

<span class="sd">    .. math:: output_i = \dfrac{input_i}{\sqrt{\sum_{i}^{C} input_i}}</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param bias: The bias added to the variance. Scalar value.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a GRN operation on tensor&#39;s channels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">GRN</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span></div>


<div class="viewcode-block" id="group_convolution"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.group_convolution">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">group_convolution</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
                      <span class="n">filters</span><span class="p">,</span>                         <span class="c1"># type: Node</span>
                      <span class="n">window_movement_strides</span><span class="p">,</span>         <span class="c1"># type: List[int]</span>
                      <span class="n">window_dilation_strides</span><span class="p">,</span>         <span class="c1"># type: List[int]</span>
                      <span class="n">padding_below</span><span class="p">,</span>                   <span class="c1"># type: List[int]</span>
                      <span class="n">padding_above</span><span class="p">,</span>                   <span class="c1"># type: List[int]</span>
                      <span class="n">data_dilation_strides</span><span class="p">,</span>           <span class="c1"># type: List[int]</span>
                      <span class="n">groups</span><span class="p">,</span>                          <span class="c1"># type: int</span>
                      <span class="n">pad_type</span><span class="o">=</span><span class="s1">&#39;EXPLICIT&#39;</span><span class="p">,</span>             <span class="c1"># type: str</span>
                      <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                       <span class="c1"># type: str</span>
                      <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform Group Convolution operation on data from input node.</span>

<span class="sd">    :param  data: The node producing input data.</span>
<span class="sd">    :param filters: The node producing filters data.</span>
<span class="sd">    :param window_movement_strides: The strides along each feature axis.</span>
<span class="sd">    :param window_dilation_strides: The dilations along each feature axis.</span>
<span class="sd">    :param padding_below: The padding added below each feature axis.</span>
<span class="sd">    :param padding_above: The padding added above each feature axis.</span>
<span class="sd">    :data_dilation_strides: The dilations along data.</span>
<span class="sd">    :param groups: The number of groups the input channels and output channels</span>
<span class="sd">                   are divided into.</span>
<span class="sd">    :param pad_type: Name describes how to perform padding.</span>
<span class="sd">                     EXPLICITI: Pad dimensions are explicity specified</span>

<span class="sd">                     SAME_LOWER: Pad dimensions computed to match input shape</span>
<span class="sd">                                 Ceil(num_dims/2) at the beginning and</span>
<span class="sd">                                 Floor(num_dims/2) at the end</span>

<span class="sd">                     SAME_UPPER: Pad dimensions computed to match input shape</span>
<span class="sd">                                 Floor(num_dims/2) at the beginning and</span>
<span class="sd">                                 Ceil(num_dims/2) at the end</span>

<span class="sd">                     VALID: No padding</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a Group Convolution operation on tensor from input node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">GroupConvolution</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span>
                            <span class="n">filters</span><span class="p">,</span>
                            <span class="n">Strides</span><span class="p">(</span><span class="n">window_movement_strides</span><span class="p">),</span>
                            <span class="n">Strides</span><span class="p">(</span><span class="n">window_dilation_strides</span><span class="p">),</span>
                            <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_below</span><span class="p">),</span>
                            <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span>
                            <span class="n">Strides</span><span class="p">(</span><span class="n">data_dilation_strides</span><span class="p">),</span>
                            <span class="n">groups</span><span class="p">,</span>
                            <span class="n">GroupConvolution</span><span class="o">.</span><span class="n">PadType</span><span class="p">(</span><span class="n">pad_type</span><span class="p">))</span></div>


<div class="viewcode-block" id="rnn_cell"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.rnn_cell">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">rnn_cell</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
             <span class="n">H_t</span><span class="p">,</span>                    <span class="c1"># type: Node</span>
             <span class="n">W</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
             <span class="n">R</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
             <span class="n">B</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
             <span class="n">hidden_size</span><span class="p">,</span>            <span class="c1"># type: int</span>
             <span class="n">activations</span><span class="p">,</span>            <span class="c1"># type: List[str]</span>
             <span class="n">activation_alpha</span><span class="p">,</span>       <span class="c1"># type: List[float]</span>
             <span class="n">activation_beta</span><span class="p">,</span>        <span class="c1"># type: List[float]</span>
             <span class="n">clip</span><span class="p">,</span>                   <span class="c1"># type: float</span>
             <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>              <span class="c1"># type: str</span>
             <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform RNNCell operation on tensor from input node.</span>

<span class="sd">    It follows notation and equations defined as in ONNX standard:</span>
<span class="sd">    https://github.com/onnx/onnx/blob/master/docs/Operators.md#RNN</span>

<span class="sd">    Note this class represents only single *cell* and not whole RNN *layer*.</span>

<span class="sd">    :param      X:                 The input tensor with shape: [batch_size, input_size].</span>
<span class="sd">    :param      H_t:               The hidden state tensor at current time step with shape:</span>
<span class="sd">                                   [batch_size, hidden_size].</span>
<span class="sd">    :param      W:                 The weight tensor with shape: [hidden_size, input_size].</span>
<span class="sd">    :param      R:                 The recurrence weight tensor with shape: [hidden_size,</span>
<span class="sd">                                   hidden_size].</span>
<span class="sd">    :param      B:                 The bias tensor for input gate with shape: [2*hidden_size].</span>
<span class="sd">    :param      hidden_size:       The number of hidden units for recurrent cell.</span>
<span class="sd">    :param      activations:       The vector of activation functions used inside recurrent cell.</span>
<span class="sd">    :param      activation_alpha:  The vector of alpha parameters for activation functions in</span>
<span class="sd">                                   order respective to activation list.</span>
<span class="sd">    :param      activation_beta:   The vector of beta parameters for activation functions in order</span>
<span class="sd">                                   respective to activation list.</span>
<span class="sd">    :param      clip:              The value defining clipping range [-clip, clip] on input of</span>
<span class="sd">                                   activation functions.</span>
<span class="sd">    :param      name:              Optional output node name.</span>
<span class="sd">    :returns:   The new node performing a RNNCell operation on tensor from input node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">RNNCell</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                   <span class="n">H_t</span><span class="p">,</span>
                   <span class="n">W</span><span class="p">,</span>
                   <span class="n">R</span><span class="p">,</span>
                   <span class="n">B</span><span class="p">,</span>
                   <span class="n">hidden_size</span><span class="p">,</span>
                   <span class="n">activations</span><span class="p">,</span>
                   <span class="n">activation_alpha</span><span class="p">,</span>
                   <span class="n">activation_beta</span><span class="p">,</span>
                   <span class="n">clip</span><span class="p">)</span></div>


<div class="viewcode-block" id="scale_shift"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.scale_shift">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">scale_shift</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, Node, Node, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform ScaleShift transformation on input node.</span>

<span class="sd">    Computes ScaleShift:</span>

<span class="sd">    .. math:: Y = scale\cdot data + shift</span>


<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param scale: The node with data tensor that scale input data.</span>
<span class="sd">    :param shift: The node with data tensor that shift input data.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a ScaleShift operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ScaleShift</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span></div>


<div class="viewcode-block" id="space_to_depth"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.space_to_depth">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">space_to_depth</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, str, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform SpaceToDepth operation on the input tensor.</span>

<span class="sd">    SpaceToDepth rearranges blocks of spatial data into depth.</span>
<span class="sd">    The operator returns a copy of the input tensor where values from the height</span>
<span class="sd">    and width dimensions are moved to the depth dimension.</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param mode: Specifies how the output depth dimension is gathered from block coordinates.</span>

<span class="sd">                 blocks_first: The output depth is gathered from [block_size, ..., block_size, C]</span>
<span class="sd">                 depth_first: The output depth is gathered from [C, block_size, ..., block_size]</span>

<span class="sd">    :param block_size: The size of the block of values to be moved. Scalar value.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a SpaceToDepth operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SpaceToDepth</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span></div>


<div class="viewcode-block" id="mvn"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.mvn">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">mvn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">normalize_variance</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Set[int], bool, float, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform Mean Variance Normalization operation on data from input node.</span>

<span class="sd">    Computes MVN on the input tensor :code:`data` (called `X`) using formula:</span>

<span class="sd">    .. math:: Y = \dfrac{X-EX}{\sqrt{E(X-EX)^2}}</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param axes: A list of axes, along which to reduce. Array of integers.</span>
<span class="sd">    :param normalize_variance: Flag that denotes if mean values are shared across channels.</span>
<span class="sd">                               Boolen value.</span>
<span class="sd">    :param eps: The number added to the variance to avoid division by zero</span>
<span class="sd">               when normalizing the value. Scalar value.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a MVN operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">MVN</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">axes</span><span class="p">),</span> <span class="n">normalize_variance</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span></div>


<div class="viewcode-block" id="quantize"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.quantize">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">quantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">new_type</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Node, Node, NumericType, Set[int], Quantize.RoundMode, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform quantize operation on data from input node.</span>

<span class="sd">    Computes quantize on the input tensor:</span>

<span class="sd">    .. math:: output = ROUND((input / scale) + zero\_point)</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param scale: Scale used for mapping.</span>
<span class="sd">    :param zero_point: Zero point used for mapping.</span>
<span class="sd">    :param new_type: Output element type.</span>
<span class="sd">    :param round_mode: Number describes how to perform ROUND function.</span>

<span class="sd">                 ROUND_NEAREST_TOWARD_INFINITY: Round to nearest integer. In case of two</span>
<span class="sd">                 equidistant integers round away from zero e.g. 2.5 -&gt; 3,  -3.5 -&gt; -4</span>

<span class="sd">                 ROUND_NEAREST_TOWARD_ZERO: Round to nearest integer. In case of two equidistant</span>
<span class="sd">                 integers round toward zero e.g. 2.5 -&gt; 2,  -3.5 -&gt; -3</span>

<span class="sd">                 ROUND_NEAREST_UPWARD: Round to nearest integer. In case of two equidistant</span>
<span class="sd">                 integers round up e.g. 2.5 -&gt; 2,  -3.5 -&gt; -3</span>

<span class="sd">                 ROUND_NEAREST_DOWNWARD: Round to nearest integer. In case of two equidistant</span>
<span class="sd">                 integers round down e.g. 2.5 -&gt; 2,  -3.5 -&gt; -4</span>

<span class="sd">                 ROUND_NEAREST_TOWARD_EVEN: Round to nearest integer. In case of two equidistant</span>
<span class="sd">                 integers round down e.g. 2.5 -&gt; 2,  -3.5 -&gt; -4</span>

<span class="sd">                 ROUND_TOWARD_INFINITY: Round to nearest integer away from zero.</span>

<span class="sd">                 ROUND_TOWARD_ZERO: Round to nearest integer toward zero.</span>

<span class="sd">                 ROUND_UP: Round to nearest integer toward infinity (ceiling).</span>

<span class="sd">                 ROUND_DOWN: Round to nearest integer toward negative infinity (floor).</span>

<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a quantize operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_element_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">new_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Quantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                    <span class="n">scale</span><span class="p">,</span>
                    <span class="n">zero_point</span><span class="p">,</span>
                    <span class="n">new_element_type</span><span class="p">,</span>
                    <span class="n">AxisSet</span><span class="p">(</span><span class="n">axes</span><span class="p">),</span>
                    <span class="n">round_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="dequantize"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.dequantize">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">dequantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">element_type</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Node, Node, NumericType, Set[int], str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform dequantize operation on data from input node.</span>

<span class="sd">    Computes dequantize on the input tensor:</span>

<span class="sd">    .. math:: output = (input - zero\_point) * scale</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param scale: Scale used for mapping.</span>
<span class="sd">    :param zero_point: Zero point used for mapping.</span>
<span class="sd">    :param element_type: Output element type.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a dequantize operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_element_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">element_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Dequantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">new_element_type</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="quantized_convolution"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.quantized_convolution">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">quantized_convolution</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
                          <span class="n">filters</span><span class="p">,</span>                   <span class="c1"># type: Node</span>
                          <span class="n">window_movement_strides</span><span class="p">,</span>   <span class="c1"># type: List[int]</span>
                          <span class="n">window_dilation_strides</span><span class="p">,</span>   <span class="c1"># type: List[int]</span>
                          <span class="n">padding_below</span><span class="p">,</span>             <span class="c1"># type: List[int]</span>
                          <span class="n">padding_above</span><span class="p">,</span>             <span class="c1"># type: List[int]</span>
                          <span class="n">data_dilation_strides</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
                          <span class="n">input_scale</span><span class="p">,</span>               <span class="c1"># type: Node</span>
                          <span class="n">input_zero_point</span><span class="p">,</span>          <span class="c1"># type: Node</span>
                          <span class="n">filter_scale</span><span class="p">,</span>              <span class="c1"># type: Node</span>
                          <span class="n">filter_zero_point</span><span class="p">,</span>         <span class="c1"># type: Node</span>
                          <span class="n">output_scale</span><span class="p">,</span>              <span class="c1"># type: Node</span>
                          <span class="n">output_zero_point</span><span class="p">,</span>         <span class="c1"># type: Node</span>
                          <span class="n">output_type</span><span class="p">,</span>               <span class="c1"># type: NumericType</span>
                          <span class="n">input_axes</span><span class="p">,</span>                <span class="c1"># type: Set[int]</span>
                          <span class="n">filter_axes</span><span class="p">,</span>               <span class="c1"># type: Set[int]</span>
                          <span class="n">output_axes</span><span class="p">,</span>               <span class="c1"># type: Set[int]</span>
                          <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                 <span class="c1"># type: str</span>
                          <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform quantized convolution operation on data from input node.</span>

<span class="sd">    :param data: The node producing the input data batch tensor.</span>
<span class="sd">    :param filters: The node producing the filters tensor.</span>
<span class="sd">    :param window_movement_strides: The window movement strides.</span>
<span class="sd">    :param window_dilation_strides: he window dilation strides.</span>
<span class="sd">    :param padding_below: The padding-below sizes.</span>
<span class="sd">    :param padding_above: The padding-above sizes.</span>
<span class="sd">    :param data_dilation_strides: The data dilation strides.</span>
<span class="sd">    :param input_scale: Scale to transform the input.</span>
<span class="sd">    :param input_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param filter_scale: Scale to transform the filters.</span>
<span class="sd">    :param filter_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param output_scale: Scale to transform the output.</span>
<span class="sd">    :param output_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param output_type: Output element type.</span>
<span class="sd">    :param input_axes: Input axes set for channel wise quantization.</span>
<span class="sd">    :param filter_axes: Filter axes set for channel wise quantization.</span>
<span class="sd">    :param output_type: Output axes set for channel wise quantization.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a quantized convolution operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_output_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">QuantizedConvolution</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                                <span class="n">filters</span><span class="p">,</span>
                                <span class="n">Strides</span><span class="p">(</span><span class="n">window_movement_strides</span><span class="p">),</span>
                                <span class="n">Strides</span><span class="p">(</span><span class="n">window_dilation_strides</span><span class="p">),</span>
                                <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_below</span><span class="p">),</span>
                                <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span>
                                <span class="n">Strides</span><span class="p">(</span><span class="n">data_dilation_strides</span><span class="p">),</span>
                                <span class="n">input_scale</span><span class="p">,</span>
                                <span class="n">input_zero_point</span><span class="p">,</span>
                                <span class="n">filter_scale</span><span class="p">,</span>
                                <span class="n">filter_zero_point</span><span class="p">,</span>
                                <span class="n">output_scale</span><span class="p">,</span>
                                <span class="n">output_zero_point</span><span class="p">,</span>
                                <span class="n">new_output_type</span><span class="p">,</span>
                                <span class="n">AxisSet</span><span class="p">(</span><span class="n">input_axes</span><span class="p">),</span>
                                <span class="n">AxisSet</span><span class="p">(</span><span class="n">filter_axes</span><span class="p">),</span>
                                <span class="n">AxisSet</span><span class="p">(</span><span class="n">output_axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="quantized_dot"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.quantized_dot">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">quantized_dot</span><span class="p">(</span><span class="n">input0</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
                  <span class="n">input1</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
                  <span class="n">reduction_axes_count</span><span class="p">,</span>        <span class="c1"># type: int</span>
                  <span class="n">input0_scale</span><span class="p">,</span>                <span class="c1"># type: Node</span>
                  <span class="n">input0_zero_point</span><span class="p">,</span>           <span class="c1"># type: Node</span>
                  <span class="n">input1_scale</span><span class="p">,</span>                <span class="c1"># type: Node</span>
                  <span class="n">input1_zero_point</span><span class="p">,</span>           <span class="c1"># type: Node</span>
                  <span class="n">output_scale</span><span class="p">,</span>                <span class="c1"># type: Node</span>
                  <span class="n">output_zero_point</span><span class="p">,</span>           <span class="c1"># type: Node</span>
                  <span class="n">output_type</span><span class="p">,</span>                 <span class="c1"># type: NumericType</span>
                  <span class="n">input0_axes</span><span class="p">,</span>                 <span class="c1"># type: Set[int]</span>
                  <span class="n">input1_axes</span><span class="p">,</span>                 <span class="c1"># type: Set[int]</span>
                  <span class="n">output_axes</span><span class="p">,</span>                 <span class="c1"># type: Set[int]</span>
                  <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                   <span class="c1"># type: str</span>
                  <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform quantized dot operation on data from input node.</span>

<span class="sd">    :param input0: The node producing the input data batch tensor.</span>
<span class="sd">    :param input1: The node producing the filters tensor.</span>
<span class="sd">    :param reduction_axes_count: Number of reduction axes.</span>
<span class="sd">    :param input0_scale: Scale to transform the input.</span>
<span class="sd">    :param input0_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param input1_scale: Scale to transform the filters.</span>
<span class="sd">    :param input1_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param output_scale: Scale to transform the output.</span>
<span class="sd">    :param output_zero_point: Zero point used for mapping.</span>
<span class="sd">    :param output_type: Output element type.</span>
<span class="sd">    :param input0_axes: Input0 axes set for channel wise quantization</span>
<span class="sd">    :param input1_axes: Input1 axes set for channel wise quantization</span>
<span class="sd">    :param output_axes: Output axes set for channel wise quantization</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a quantized dot operation on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_output_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">QuantizedDot</span><span class="p">(</span><span class="n">input0</span><span class="p">,</span>
                        <span class="n">input1</span><span class="p">,</span>
                        <span class="n">reduction_axes_count</span><span class="p">,</span>
                        <span class="n">input0_scale</span><span class="p">,</span>
                        <span class="n">input0_zero_point</span><span class="p">,</span>
                        <span class="n">input1_scale</span><span class="p">,</span>
                        <span class="n">input1_zero_point</span><span class="p">,</span>
                        <span class="n">output_scale</span><span class="p">,</span>
                        <span class="n">output_zero_point</span><span class="p">,</span>
                        <span class="n">new_output_type</span><span class="p">,</span>
                        <span class="n">AxisSet</span><span class="p">(</span><span class="n">input0_axes</span><span class="p">),</span>
                        <span class="n">AxisSet</span><span class="p">(</span><span class="n">input1_axes</span><span class="p">),</span>
                        <span class="n">AxisSet</span><span class="p">(</span><span class="n">output_axes</span><span class="p">))</span></div>


<span class="c1"># Unary ops</span>
<div class="viewcode-block" id="absolute"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.absolute">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">absolute</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = abs(x) to the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with Abs operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Abs</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="acos"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.acos">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">acos</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply inverse cosine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with arccos operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Acos</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="asin"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.asin">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">asin</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply inverse sine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with arcsin operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Asin</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="atan"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.atan">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">atan</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply inverse tangent function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with arctan operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Atan</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="cos"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.cos">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">cos</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply cosine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with cos operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Cos</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="cosh"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.cosh">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">cosh</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply hyperbolic cosine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with cosh operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Cosh</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="sqrt"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.sqrt">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies square root to the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: The new node with sqrt operation applied element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Sqrt</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="exp"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.exp">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">exp</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies exp to the input node element-wise.</span>

<span class="sd">    :param node: The node providing data for operation.</span>
<span class="sd">    :param name: The optional name for new output node.</span>
<span class="sd">    :return: The new node performing natural exponential operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Exp</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="log"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.log">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">log</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies natural logarithm to the input node element-wise.</span>

<span class="sd">    :param node: The input node providing data for operation.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The new node performing log operation element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Log</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="negative"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.negative">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">negative</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = -x to the input node elementwise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Negative</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="floor"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.floor">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">floor</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies floor to the input node element-wise.</span>

<span class="sd">    :param node: The input node providing data.</span>
<span class="sd">    :param name: The optional name for new output node.</span>
<span class="sd">    :return: The node performing element-wise floor operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Floor</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="ceiling"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.ceiling">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">ceiling</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies ceiling to the input node element-wise.</span>

<span class="sd">    :param node: The node providing data to ceiling operation.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    :return: The node performing element-wise ceiling.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Ceiling</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="reshape"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.reshape">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">input_order</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, List[int], List[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return reshaped node according to provided parameters.</span>

<span class="sd">    :param node: The tensor we want to reshape.</span>
<span class="sd">    :param input_order: The order in which to iterate over input axes of input tensor.</span>
<span class="sd">    :param output_shape: The new shape for input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">input_order</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">Reshape</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisVector</span><span class="p">(</span><span class="n">input_order</span><span class="p">),</span> <span class="n">Shape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="relu"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.relu">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform rectified linear unit operation on input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: The optional ouptut node name.</span>
<span class="sd">    :return: The new node performing relu operation on its input element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Relu</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="sign"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.sign">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">sign</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform element-wise sign operation.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: The optional new name for ouptut node.</span>
<span class="sd">    :return: The node with mapped elements of the input tensor to -1 (if it is negative),</span>
<span class="sd">             0 (if it is zero), or 1 (if it is positive).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Sign</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="sin"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.sin">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">sin</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply sine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with sin operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Sin</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="sinh"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.sinh">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">sinh</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply hyperbolic sine function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with sin operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Sinh</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="tan"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.tan">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">tan</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply tangent function on the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with tan operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tan</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<span class="c1"># Binary ops</span>
<div class="viewcode-block" id="divide"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.divide">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">divide</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = A/B to the input nodes element-wise.</span>

<span class="sd">    :param left_node: The node providing dividend data.</span>
<span class="sd">    :param right_node: The node providing divisor data.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    :return: The node performing element-wise division.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Divide</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="multiply"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.multiply">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">multiply</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = A*B to the input nodes elementwise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Multiply</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="subtract"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.subtract">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">subtract</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = A-B to the input nodes element-wise.</span>

<span class="sd">    :param left_node: The node providing data for left hand side of operator.</span>
<span class="sd">    :param right_node: The node providing data for right hand side of operator.</span>
<span class="sd">    :param name: The optional name for output node.</span>
<span class="sd">    :return: The new output node performing subtraction operation on both tensors element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Subtract</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="add"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.add">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies f(x) = A+B to the input nodes element-wise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Add</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="minimum"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.minimum">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">minimum</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies the minimum operation to input nodes elementwise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Minimum</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="maximum"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.maximum">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">maximum</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies the maximum operation to input nodes elementwise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Maximum</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="power"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.power">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">power</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which perform element-wise exponentiation operation.</span>

<span class="sd">    :param left_node: The node providing the base of operation.</span>
<span class="sd">    :param right_node: The node providing the exponent of operation.</span>
<span class="sd">    :param name: The optional name for the new output node.</span>
<span class="sd">    :return: The new node performing element-wise exponentiation operation on input nodes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Power</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<span class="c1"># Logical ops</span>
<div class="viewcode-block" id="equal"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.equal">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">equal</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if input nodes are equal element-wise.</span>

<span class="sd">    :param left_node: The first input node for equal operation.</span>
<span class="sd">    :param right_node: The second input node for equal operation.</span>
<span class="sd">    :param name: The optional name for output new node.</span>
<span class="sd">    :return: The node performing element-wise equality check.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Equal</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="not_equal"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.not_equal">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">not_equal</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if input nodes are unequal element-wise.</span>

<span class="sd">    :param left_node: The first input node for not-equal operation.</span>
<span class="sd">    :param right_node: The second input node for not-equal operation.</span>
<span class="sd">    :param name: The optional name for output new node.</span>
<span class="sd">    :return: The node performing element-wise inequality check.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">NotEqual</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="greater"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.greater">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">greater</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if left input node is greater than the right node element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing element-wise check whether left_node is greater than right_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Greater</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="greater_eq"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.greater_eq">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">greater_eq</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if left node is greater or equal to the right node element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing element-wise check whether left_node is greater than or equal</span>
<span class="sd">             right_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">GreaterEq</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="less"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.less">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">less</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if left input node is less than the right node element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing element-wise check whether left_node is less than the right_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Less</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="less_eq"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.less_eq">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">less_eq</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which checks if left input node is less or equal the right node element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing element-wise check whether left_node is less than or equal the</span>
<span class="sd">             right_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">LessEq</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="logical_and"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.logical_and">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">logical_and</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which perform logical and operation on input nodes element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing logical and operation on input nodes corresponding elements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">And</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="logical_or"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.logical_or">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">logical_or</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, NodeInput, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which performs logical or operation on input nodes element-wise.</span>

<span class="sd">    :param left_node: The first input node providing data.</span>
<span class="sd">    :param right_node: The second input node providing data.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The node performing logical or operation on input nodes corresponding elements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Or</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span></div>


<div class="viewcode-block" id="logical_not"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.logical_not">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">logical_not</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies logical negation to the input node elementwise.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Not</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="squared_difference"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.squared_difference">[docs]</a><span class="nd">@binary_op</span>
<span class="k">def</span> <span class="nf">squared_difference</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, Node, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform an element-wise squared difference between two tensors.</span>

<span class="sd">    .. math:: y[i] = (x_1[i] - x_2[i])^2</span>

<span class="sd">    :param x1: The node with first input tensor.</span>
<span class="sd">    :param x2: The node with second input tensor.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: The new node performing a squared difference between two tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SquaredDifference</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span></div>


<span class="c1"># Extend Node class to support binary operators</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__add__</span> <span class="o">=</span> <span class="n">add</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__sub__</span> <span class="o">=</span> <span class="n">subtract</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__mul__</span> <span class="o">=</span> <span class="n">multiply</span>
<span class="n">Node</span><span class="o">.</span><span class="n">__div__</span> <span class="o">=</span> <span class="n">divide</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__truediv__</span> <span class="o">=</span> <span class="n">divide</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__radd__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">:</span> <span class="n">add</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__rsub__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">:</span> <span class="n">subtract</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__rmul__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">:</span> <span class="n">multiply</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
<span class="n">Node</span><span class="o">.</span><span class="n">__rdiv__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">:</span> <span class="n">divide</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__rtruediv__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">:</span> <span class="n">divide</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__eq__</span> <span class="o">=</span> <span class="n">equal</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__ne__</span> <span class="o">=</span> <span class="n">not_equal</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__lt__</span> <span class="o">=</span> <span class="n">less</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__le__</span> <span class="o">=</span> <span class="n">less_eq</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__gt__</span> <span class="o">=</span> <span class="n">greater</span>
<span class="n">Node</span><span class="o">.</span><span class="fm">__ge__</span> <span class="o">=</span> <span class="n">greater_eq</span>


<span class="c1"># Custom ops</span>
<div class="viewcode-block" id="broadcast"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.broadcast">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">broadcast</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">,</span> <span class="n">broadcast_axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, TensorShape, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Create a node which broadcasts the input node&#39;s values along specified axes to a desired shape.</span>

<span class="sd">    :param node: The node with input tensor data.</span>
<span class="sd">    :param new_shape: The new shape we want to broadcast tensor to.</span>
<span class="sd">    :param broadcast_axes: The axis positions (0-based) in the result that are being broadcast.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with broadcast shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Broadcast</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">),</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">broadcast_axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="broadcast_to"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.broadcast_to">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">broadcast_to</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, TensorShape, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Create a node which broadcasts the input node&#39;s values to a desired shape.</span>

<span class="sd">    `broadcast_to` will attempt to automatically determine which axes need broadcasting.</span>

<span class="sd">    The optional `axis` parameter specifies the starting axis position (0-based) in the output</span>
<span class="sd">    shape from which the current shape of the tensor matches the desired new shape.</span>

<span class="sd">    e.g. current_shape: [4, 5], new_shape: [2, 3, 4, 5, 6], axis: 2</span>

<span class="sd">    By using the `axis` parameter you can control which output axis to broadcast along.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; input_node = ng.constant([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; current_shape = [3]</span>
<span class="sd">    &gt;&gt;&gt; new_shape = [3, 3]</span>
<span class="sd">    &gt;&gt;&gt; ng.broadcast_to(input_node, new_shape, axis=1)</span>
<span class="sd">    array([[1, 2, 3],</span>
<span class="sd">           [1, 2, 3],</span>
<span class="sd">           [1, 2, 3]])</span>

<span class="sd">    &gt;&gt;&gt; ng.broadcast_to(input_node, new_shape, axis=0)</span>
<span class="sd">    array([[1, 1, 1],</span>
<span class="sd">           [2, 2, 2],</span>
<span class="sd">           [3, 3, 3]])</span>

<span class="sd">    If the `axis` parameter is not specified, `broadcast_to` will attempt to match shapes,</span>
<span class="sd">    assuming the current shape matches the rightmost positions of the desired new shape.</span>
<span class="sd">    This behaviour is similar to NumPy&#39;s broadcasting.</span>

<span class="sd">    i.e. default `axis = len(new_shape) - len(current_shape)`</span>

<span class="sd">    :param node: The node with input tensor data.</span>
<span class="sd">    :param new_shape: The new shape we want to broadcast tensor to.</span>
<span class="sd">    :param axis: The axis along which we perform broadcasting.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with broadcast shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Broadcast</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">),</span> <span class="n">get_broadcast_axes</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span></div>


<div class="viewcode-block" id="fake_quantize"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.fake_quantize">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">fake_quantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">input_low</span><span class="p">,</span> <span class="n">input_high</span><span class="p">,</span> <span class="n">output_low</span><span class="p">,</span> <span class="n">output_high</span><span class="p">,</span> <span class="n">levels</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Node, Node, Node, Node, int, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform an element-wise linear quantization on input data.</span>

<span class="sd">    Input floating point values are quantized into a discrete set of floating point values.</span>

<span class="sd">    .. code-block:: python</span>
<span class="sd">        if x &lt;= input_low:</span>
<span class="sd">            output = output_low</span>
<span class="sd">        if x &gt; input_high:</span>
<span class="sd">            output = output_high</span>
<span class="sd">        else:</span>
<span class="sd">            output = fake_quantize(output)</span>

<span class="sd">    Fake quantize uses the following logic:</span>

<span class="sd">    .. math:: output =</span>
<span class="sd">            \dfrac{round( \dfrac{data - input\_low}{(input\_high - input\_low)\cdot (levels-1)})}</span>
<span class="sd">            {(levels-1)\cdot (output\_high - output\_low)} + output\_low</span>

<span class="sd">    :param data:         The node with data tensor.</span>
<span class="sd">    :param input_low:    The node with the minimum for input values.</span>
<span class="sd">    :param input_high:   The node with the maximum for input values.</span>
<span class="sd">    :param output_low:   The node with the minimum quantized value.</span>
<span class="sd">    :param output_high:  The node with the maximum quantized value.</span>
<span class="sd">    :param levels:       The number of quantization levels. Integer value.</span>
<span class="sd">    :return: New node with quantized value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">FakeQuantize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">input_low</span><span class="p">,</span> <span class="n">input_high</span><span class="p">,</span> <span class="n">output_low</span><span class="p">,</span> <span class="n">output_high</span><span class="p">,</span> <span class="n">levels</span><span class="p">)</span></div>


<div class="viewcode-block" id="gemm"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.gemm">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">gemm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
         <span class="n">B</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
         <span class="n">C</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
         <span class="n">alpha</span><span class="p">,</span>                  <span class="c1"># type: ScalarData</span>
         <span class="n">beta</span><span class="p">,</span>                   <span class="c1"># type: ScalarData</span>
         <span class="n">transA</span><span class="p">,</span>                 <span class="c1"># type: bool</span>
         <span class="n">transB</span><span class="p">,</span>                 <span class="c1"># type: bool</span>
         <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>              <span class="c1"># type: str</span>
         <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform General matrix-matrix multiplication on input tensors A, B and C.</span>

<span class="sd">    Computes:</span>

<span class="sd">    .. math:: Y = alpha\cdot A&#39;\cdot B&#39; +  beta\cdot C</span>

<span class="sd">    :code:`A&#39;` is the transpose of matrix :code:`A` with shape (M, K),</span>
<span class="sd">    if :code:`transA` is :code:`True`, otherwise :code:`A` with shape (K, N).</span>

<span class="sd">    :code:`B&#39;` is the transpose of matrix :code:`B` with shape (K, N),</span>
<span class="sd">    if :code:`transB` is :code:`True`, otherwise :code:`B` with shape (N, K).</span>

<span class="sd">    :code:`C`: Matrix broadcastable to shape (M, N).</span>

<span class="sd">    :code:`Y`: Matrix with shape (M, N).</span>

<span class="sd">    :param A: The node with input tensor A.</span>
<span class="sd">    :param B: The node with input tensor B.</span>
<span class="sd">    :param C: The node with input tensor C.</span>
<span class="sd">    :param alpha: Scalar multiplier for the product of input tensors A * B.</span>
<span class="sd">    :param beta: Scalar multiplier for input tensor C.</span>
<span class="sd">    :param transA: Whether A should be transposed. Boolean value.</span>
<span class="sd">    :param transB: Whether B should be transposed. Boolean value.</span>
<span class="sd">    :param name: Optional name for the output node.</span>
<span class="sd">    :return: Return node with tensor of shape (M, N).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Gemm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">transA</span><span class="p">,</span> <span class="n">transB</span><span class="p">)</span></div>


<div class="viewcode-block" id="convert"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.convert">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, NumericType, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which casts input node values to specified type.&quot;&quot;&quot;</span>
    <span class="n">new_element_type</span> <span class="o">=</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">new_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Convert</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_element_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="depth_to_space"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.depth_to_space">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">depth_to_space</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, str, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Rearranges input tensor from depth into blocks of spatial data.</span>

<span class="sd">    Values from the height and width dimensions are moved to the depth dimension.</span>

<span class="sd">    Input tensor has shape [N,C,H,W], where N is the batch axis, C is the channel or depth,</span>
<span class="sd">    H is the height and W is the width.</span>

<span class="sd">    Output node produces a tensor with shape:</span>

<span class="sd">    [N, C * :code:`block_size` * :code:`block_size`, H / :code:`block_size`, W / :code:`block_size`]</span>

<span class="sd">    :param node: The node with input tensor data.</span>
<span class="sd">    :param mode: Specifies how the input depth dimension is split to block coordinates</span>

<span class="sd">                 blocks_first: The input is divided to [block_size, ..., block_size, new_depth]</span>
<span class="sd">                 depth_first: The input is divided to [new_depth, block_size, ..., block_size]</span>

<span class="sd">    :param block_size: The size of the spatial block of values describing</span>
<span class="sd">                       how the tensor&#39;s data is to be rearranged.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing an DepthToSpace operation on its input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DepthToSpace</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span></div>


<div class="viewcode-block" id="gelu"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.gelu">[docs]</a><span class="k">def</span> <span class="nf">gelu</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (NodeInput, str) -&gt; Node</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform Gaussian Error Linear Unit operation element-wise on data from input node.</span>

<span class="sd">    Computes GELU function:</span>

<span class="sd">    .. math:: f(x) = 0.5\cdot x\cdot(1 + erf( \dfrac{x}{\sqrt{2}})</span>

<span class="sd">    For more information refer to:</span>
<span class="sd">    `Gaussian Error Linear Unit (GELU) &lt;https://arxiv.org/pdf/1606.08415.pdf&gt;`_</span>

<span class="sd">    :param node: Input tensor. One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a GELU operation on its input data element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Gelu</span><span class="p">(</span><span class="n">as_node</span><span class="p">(</span><span class="n">node</span><span class="p">))</span></div>


<div class="viewcode-block" id="select"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.select">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">selection_node</span><span class="p">,</span> <span class="n">input_node1</span><span class="p">,</span> <span class="n">input_node2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Node, Node, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform an element-wise selection operation on input tensors.</span>

<span class="sd">    :param selection_node: The node providing selection values of `bool` type.</span>
<span class="sd">    :param input_node1: The node providing data to be selected if respective `selection_node`</span>
<span class="sd">                        item value is `True`.</span>
<span class="sd">    :param input_node2: The node providing data to be selected if respective `selection_node`</span>
<span class="sd">                        item value is `False`.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The new node with values selected according to provided arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Select</span><span class="p">(</span><span class="n">selection_node</span><span class="p">,</span> <span class="n">input_node1</span><span class="p">,</span> <span class="n">input_node2</span><span class="p">)</span></div>


<span class="c1"># Non-linear ops</span>
<div class="viewcode-block" id="tanh"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.tanh">[docs]</a><span class="nd">@unary_op</span>
<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which applies hyperbolic tangent to the input node element-wise.</span>

<span class="sd">    :param node: One of: input node, array or scalar.</span>
<span class="sd">    :param name: Optional new name for output node.</span>
<span class="sd">    :return: New node with tanh operation applied on it.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tanh</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<div class="viewcode-block" id="clamp"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.clamp">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">clamp</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (NodeInput, ScalarData, ScalarData, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform clamp element-wise on data from input node.</span>

<span class="sd">    Performs a clipping operation on an input value between a pair of boundary values.</span>

<span class="sd">    For each element in :code:`data`, if the element&#39;s value is lower than :code:`min_value`,</span>
<span class="sd">    it will be replaced with :code:`min_value`. If the value is higher than :code:`max_value`,</span>
<span class="sd">    it will be replaced by :code:`max_value`.</span>
<span class="sd">    Intermediate values of :code:`data` are returned without change.</span>

<span class="sd">    Clamp uses the following logic:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        if data &lt; min_value:</span>
<span class="sd">            data=min_value</span>
<span class="sd">        elif data &gt; max_value:</span>
<span class="sd">            data=max_value</span>

<span class="sd">    :param data: Input tensor. One of: input node, array or scalar.</span>
<span class="sd">    :param min_value: The lower bound of the &lt;min_value;max_value&gt; range. Scalar value.</span>
<span class="sd">    :param max_value: The upper bound of the &lt;min_value;max_value&gt; range. Scalar value.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a clamp operation on its input data element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Clamp</span><span class="p">(</span><span class="n">as_node</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span></div>


<span class="c1"># matmul ops</span>
<div class="viewcode-block" id="dot"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.dot">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">reduction_axes_count</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Node, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node which performs generalized dot product of two input nodes.</span>

<span class="sd">    This operation is capable of performing scalar-tensor, matrix-vector product and matrix</span>
<span class="sd">    multiplication.</span>

<span class="sd">    :param left_node: The node providing left hand side data.</span>
<span class="sd">    :param right_node: The node providing right hand side data.</span>
<span class="sd">    :param reduction_axes_count: The number of axes to reduce during dot-product.</span>
<span class="sd">    :param name: The optional name for output node.</span>
<span class="sd">    :return: The new node performing dot-product on input two nodes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">reduction_axes_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Dot</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Dot</span><span class="p">(</span><span class="n">left_node</span><span class="p">,</span> <span class="n">right_node</span><span class="p">,</span> <span class="n">reduction_axes_count</span><span class="p">)</span></div>


<span class="c1"># convpool ops</span>
<div class="viewcode-block" id="convolution"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.convolution">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">convolution</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span>                     <span class="c1"># type: Node</span>
                <span class="n">filter_weights</span><span class="p">,</span>                 <span class="c1"># type: Node</span>
                <span class="n">filter_strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>            <span class="c1"># type: List[int]</span>
                <span class="n">filter_dilation_strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>   <span class="c1"># type: List[int]</span>
                <span class="n">padding_below</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>             <span class="c1"># type: List[int]</span>
                <span class="n">padding_above</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>             <span class="c1"># type: List[int]</span>
                <span class="n">data_dilation_strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
                <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                      <span class="c1"># type: str</span>
                <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node performing batched convolution operation.</span>

<span class="sd">    :param data_batch: The node providing data batch tensor.</span>
<span class="sd">    :param filter_weights: The node providing filters tensor.</span>
<span class="sd">    :param filter_strides: The kernel window movement strides.</span>
<span class="sd">    :param filter_dilation_strides: The filters dilation strides.</span>
<span class="sd">    :param padding_below: The number of zero padding elements to add on each axis below 0</span>
<span class="sd">                          coordinate.</span>
<span class="sd">    :param padding_above: The number of zero padding elements to add on each axis above max</span>
<span class="sd">                          coordinate.</span>
<span class="sd">    :param data_dilation_strides: The data batch dilation strides.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: New node performing batched convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spatial_dim_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">filter_strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filter_strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">filter_dilation_strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filter_dilation_strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_above</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_above</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_below</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_below</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">data_dilation_strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data_dilation_strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>

    <span class="k">return</span> <span class="n">Convolution</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span> <span class="n">filter_weights</span><span class="p">,</span> <span class="n">Strides</span><span class="p">(</span><span class="n">filter_strides</span><span class="p">),</span>
                       <span class="n">Strides</span><span class="p">(</span><span class="n">filter_dilation_strides</span><span class="p">),</span> <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_below</span><span class="p">),</span>
                       <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span> <span class="n">Strides</span><span class="p">(</span><span class="n">data_dilation_strides</span><span class="p">))</span></div>


<div class="viewcode-block" id="convolution_backprop_data"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.convolution_backprop_data">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">convolution_backprop_data</span><span class="p">(</span><span class="n">data_batch_shape</span><span class="p">,</span>                      <span class="c1"># type: TensorShape</span>
                              <span class="n">filters</span><span class="p">,</span>                               <span class="c1"># type: Node</span>
                              <span class="n">output_delta</span><span class="p">,</span>                          <span class="c1"># type: Node</span>
                              <span class="n">window_movement_strides_forward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: List[int]</span>
                              <span class="n">window_dilation_strides_forward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: List[int]</span>
                              <span class="n">padding_below_forward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>            <span class="c1"># type: List[int]</span>
                              <span class="n">padding_above_forward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>            <span class="c1"># type: List[int]</span>
                              <span class="n">data_dilation_strides_forward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>    <span class="c1"># type: List[int]</span>
                              <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>                             <span class="c1"># type: str</span>
                              <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return node performing a batched-convolution data batch-backprop operation.</span>

<span class="sd">    :param data_batch_shape: The shape of the data batch from forward-prop.</span>
<span class="sd">    :param filters: The node producing the filters from forward-prop.</span>
<span class="sd">    :param output_delta: The node producing output delta.</span>
<span class="sd">    :param window_movement_strides_forward: The window movement strides from forward-prop.</span>
<span class="sd">    :param window_dilation_strides_forward: The window dilation strides from forward-prop.</span>
<span class="sd">    :param padding_below_forward: The padding-below sizes from forward-prop.</span>
<span class="sd">    :param padding_above_forward: The padding-above sizes from forward-prop.</span>
<span class="sd">    :param data_dilation_strides_forward: The data dilation strides from forward-prop.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spatial_dim_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_batch_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">window_movement_strides_forward</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">window_movement_strides_forward</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">window_dilation_strides_forward</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">window_dilation_strides_forward</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_below_forward</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_below_forward</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_above_forward</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_above_forward</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">data_dilation_strides_forward</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data_dilation_strides_forward</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>

    <span class="k">return</span> <span class="n">ConvolutionBackpropData</span><span class="p">(</span><span class="n">Shape</span><span class="p">(</span><span class="n">data_batch_shape</span><span class="p">),</span> <span class="n">filters</span><span class="p">,</span> <span class="n">output_delta</span><span class="p">,</span>
                                   <span class="n">Strides</span><span class="p">(</span><span class="n">window_movement_strides_forward</span><span class="p">),</span>
                                   <span class="n">Strides</span><span class="p">(</span><span class="n">window_dilation_strides_forward</span><span class="p">),</span>
                                   <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_below_forward</span><span class="p">),</span>
                                   <span class="n">CoordinateDiff</span><span class="p">(</span><span class="n">padding_above_forward</span><span class="p">),</span>
                                   <span class="n">Strides</span><span class="p">(</span><span class="n">data_dilation_strides_forward</span><span class="p">))</span></div>


<div class="viewcode-block" id="avg_pool"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.avg_pool">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">avg_pool</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span>             <span class="c1"># type: Node</span>
             <span class="n">window_shape</span><span class="p">,</span>           <span class="c1"># type: TensorShape</span>
             <span class="n">window_strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>    <span class="c1"># type: List[int]</span>
             <span class="n">padding_below</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: TensorShape</span>
             <span class="n">padding_above</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: TensorShape</span>
             <span class="n">include_padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># type: bool</span>
             <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>              <span class="c1"># type: str</span>
             <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return average pooling node.</span>

<span class="sd">    :param data_batch: The input node providing data.</span>
<span class="sd">    :param window_shape: The pooling window shape.</span>
<span class="sd">    :param window_strides: The window movement strides.</span>
<span class="sd">    :param padding_below: The input data optional padding below filled with zeros.</span>
<span class="sd">    :param padding_above: The input data optional padding below filled with zeros.</span>
<span class="sd">    :param include_padding: Whether or not to include zero padding in average computations.</span>
<span class="sd">    :param name: Optional name for the new output node.</span>
<span class="sd">    :return: New node with AvgPool operation applied on its data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spatial_dim_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">window_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">window_strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">window_strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_above</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_above</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>
    <span class="k">if</span> <span class="n">padding_below</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_below</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">spatial_dim_count</span>

    <span class="k">return</span> <span class="n">AvgPool</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">window_shape</span><span class="p">),</span> <span class="n">Strides</span><span class="p">(</span><span class="n">window_strides</span><span class="p">),</span> <span class="n">Shape</span><span class="p">(</span><span class="n">padding_below</span><span class="p">),</span>
                   <span class="n">Shape</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span> <span class="n">include_padding</span><span class="p">)</span></div>


<div class="viewcode-block" id="max_pool"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.max_pool">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>                      <span class="c1"># type: Node</span>
             <span class="n">window_shape</span><span class="p">,</span>           <span class="c1"># type: TensorShape</span>
             <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>           <span class="c1"># type: List[int]</span>
             <span class="n">padding_above</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
             <span class="n">padding_below</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
             <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>              <span class="c1"># type: str</span>
             <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return max pooling node.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">window_shape</span><span class="p">)</span>  <span class="c1"># Default to as many 1s as spatial dimensions of input.</span>
    <span class="k">if</span> <span class="n">padding_above</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_above</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">window_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">padding_below</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_below</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">window_shape</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MaxPool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">window_shape</span><span class="p">),</span> <span class="n">Strides</span><span class="p">(</span><span class="n">strides</span><span class="p">),</span>
                   <span class="n">Shape</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span> <span class="n">Shape</span><span class="p">(</span><span class="n">padding_below</span><span class="p">))</span></div>


<span class="c1"># reduction ops</span>
<div class="viewcode-block" id="sum"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.sum">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform element-wise sums of the input tensor, eliminating the specified reduction axes.</span>

<span class="sd">    :param node: The node providing data for operation.</span>
<span class="sd">    :param reduction_axes: The axes to eliminate through summation.</span>
<span class="sd">    :param name: The optional new name for ouptut node.</span>
<span class="sd">    :return: The new node performing summation along `reduction_axes` element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Sum</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">get_reduction_axes</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="p">)))</span></div>


<div class="viewcode-block" id="max"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.max">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Max-reduction operation on input tensor, eliminating the specified reduction axes.</span>

<span class="sd">    :param node: The tensor we want to max-reduce.</span>
<span class="sd">    :param reduction_axes: The axes to eliminate through max operation.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Max</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">get_reduction_axes</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="p">)))</span></div>


<div class="viewcode-block" id="min"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.min">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">min</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Min-reduction operation on input tensor, eliminating the specified reduction axes.</span>

<span class="sd">    :param node: The tensor we want to min-reduce.</span>
<span class="sd">    :param reduction_axes: The axes to eliminate through min operation.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Min</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">get_reduction_axes</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="p">)))</span></div>


<div class="viewcode-block" id="prelu"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.prelu">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">prelu</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, Node, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform Parametrized Relu operation element-wise on data from input node.</span>

<span class="sd">    PRelu uses the following logic:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        if data &lt; 0:</span>
<span class="sd">            data = data * slope</span>
<span class="sd">        elif data &gt;= 0:</span>
<span class="sd">            data = data</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param slope: The node with the multipliers for negative values.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a PRelu operation on tensor&#39;s channels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">PRelu</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">slope</span><span class="p">)</span></div>


<div class="viewcode-block" id="hard_sigmoid"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.hard_sigmoid">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">hard_sigmoid</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, float, float, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform Hard Sigmoid operation element-wise on data from input node.</span>

<span class="sd">    Hard Sigmoid uses the following logic:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        y = max(0, min(1, alpha * data + beta))</span>

<span class="sd">    :param data: The node with data tensor.</span>
<span class="sd">    :param alpha: Alpha parameter. Scalar value.</span>
<span class="sd">    :param beta: Beta parameter. Scalar value.</span>
<span class="sd">    :param name: Optional output node name.</span>
<span class="sd">    :return: The new node performing a Hard Sigmoid element-wise on input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">HardSigmoid</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span></div>


<div class="viewcode-block" id="prod"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.prod">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">prod</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Product-reduction operation on input tensor, eliminating the specified reduction axes.</span>

<span class="sd">    :param node: The tensor we want to product-reduce.</span>
<span class="sd">    :param reduction_axes: The axes to eliminate through product operation.</span>
<span class="sd">    :param name: Optional name for output node.</span>
<span class="sd">    :return: The new node performing product-reduction operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Product</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">get_reduction_axes</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reduction_axes</span><span class="p">)))</span></div>


<span class="c1"># reshape ops</span>
<div class="viewcode-block" id="slice"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.slice">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">lower_bounds</span><span class="p">,</span> <span class="n">upper_bounds</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># type: (Node, List[int], List[int], List[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Take a slice of an input tensor, (sub-tensor) that resides within a bounding box.</span>

<span class="sd">    Optionally this function may be provided with stride along each axis.</span>

<span class="sd">    :param node: The tensor we want to slice.</span>
<span class="sd">    :param lower_bounds: The (inclusive) lower-bound coordinates for the tensor slice.</span>
<span class="sd">    :param upper_bounds: The (exclusive) upper-bound coordinates for the tensor slice.</span>
<span class="sd">    :param strides: The strides for the tensor slice.</span>
<span class="sd">    :param name: Optional name for the output node.</span>
<span class="sd">    :return: Return node that represents a slice of input nodes data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Slice</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">lower_bounds</span><span class="p">),</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">upper_bounds</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Slice</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">lower_bounds</span><span class="p">),</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">upper_bounds</span><span class="p">),</span> <span class="n">Strides</span><span class="p">(</span><span class="n">strides</span><span class="p">))</span></div>


<div class="viewcode-block" id="concat"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.concat">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (List[Node], int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Concatenate input nodes into single new node along specified axis.</span>

<span class="sd">    :param nodes: The nodes we want concatenate into single new node.</span>
<span class="sd">    :param axis: The axis along which we want to concatenate input nodes.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: Return new node that is a concatenation of input nodes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Concat</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="softmax"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.softmax">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, Iterable[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Apply softmax operation on each element of input tensor.</span>

<span class="sd">    :param node: The tensor providing input data.</span>
<span class="sd">    :param axes: The list of axes indices which are used to calculate divider of</span>
<span class="sd">                 the softmax function.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: The new node with softmax operation applied on each element.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="nb">set</span><span class="p">):</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Softmax</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="pad"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.pad">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span>          <span class="c1"># type: Node</span>
        <span class="n">value</span><span class="p">,</span>               <span class="c1"># type: Node</span>
        <span class="n">padding_below</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: TensorShape</span>
        <span class="n">padding_above</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: TensorShape</span>
        <span class="n">padding_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: TensorShape</span>
        <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>           <span class="c1"># type: str</span>
        <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return padding node.</span>

<span class="sd">    :param data_batch: The input node providing data.</span>
<span class="sd">    :param value: The node producing the scalar value to be inserted for padding.</span>
<span class="sd">    :param padding_below: The padding-below widths.</span>
<span class="sd">    :param padding_above: The padding-above widths.</span>
<span class="sd">    :param padding_in: The interior-padding widths.</span>
<span class="sd">    :param name: The optional new name for output node.</span>
<span class="sd">    :return: Return node that represents a padding of input nodes data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dim_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">padding_above</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_above</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_count</span>
    <span class="k">if</span> <span class="n">padding_below</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_below</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_count</span>
    <span class="k">if</span> <span class="n">padding_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding_in</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_count</span>

    <span class="k">return</span> <span class="n">Pad</span><span class="p">(</span><span class="n">data_batch</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">padding_below</span><span class="p">),</span> <span class="n">Shape</span><span class="p">(</span><span class="n">padding_above</span><span class="p">),</span> <span class="n">Shape</span><span class="p">(</span><span class="n">padding_in</span><span class="p">))</span></div>


<div class="viewcode-block" id="one_hot"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.one_hot">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">one_hot_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, TensorShape, int, str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Create node performing one-hot encoding on input data.</span>

<span class="sd">    :param node: The input node providing data for operation.</span>
<span class="sd">    :param shape: The output node shape including the new one-hot axis.</span>
<span class="sd">    :param one_hot_axis: The index within the output shape of the new one-hot axis.</span>
<span class="sd">    :param name: The optional name for new output node.</span>
<span class="sd">    :return: New node performing one-hot operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">OneHot</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Shape</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">one_hot_axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="replace_slice"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.replace_slice">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">replace_slice</span><span class="p">(</span><span class="n">dest_node</span><span class="p">,</span>        <span class="c1"># type: Node</span>
                  <span class="n">src_node</span><span class="p">,</span>         <span class="c1"># type: Node</span>
                  <span class="n">lower_bounds</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
                  <span class="n">upper_bounds</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
                  <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>     <span class="c1"># type: List[int]</span>
                  <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>        <span class="c1"># type: str</span>
                  <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return a copy of `dest_node` with the specified slice overwritten by the `src_node` data.</span>

<span class="sd">    :param dest_node: The node providing data to be overwritten by the specified slice.</span>
<span class="sd">    :param src_node: The node providing data for overwriting.</span>
<span class="sd">    :param lower_bounds: The (inclusive) lower-bound coordinates for the replaced slice.</span>
<span class="sd">    :param upper_bounds: The (exclusive) upper-bound coordinates for the replaced slice.</span>
<span class="sd">    :param strides: The strides for the replaced slice.</span>
<span class="sd">    :param name: The optional name for the output new node.</span>
<span class="sd">    :return: The new node with copy of `dest_node` with the specified slice overwritten</span>
<span class="sd">             by the `src_node`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">strides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ReplaceSlice</span><span class="p">(</span><span class="n">dest_node</span><span class="p">,</span> <span class="n">src_node</span><span class="p">,</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">lower_bounds</span><span class="p">),</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">upper_bounds</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ReplaceSlice</span><span class="p">(</span><span class="n">dest_node</span><span class="p">,</span> <span class="n">src_node</span><span class="p">,</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">lower_bounds</span><span class="p">),</span> <span class="n">Coordinate</span><span class="p">(</span><span class="n">upper_bounds</span><span class="p">),</span>
                            <span class="n">Strides</span><span class="p">(</span><span class="n">strides</span><span class="p">))</span></div>


<div class="viewcode-block" id="reverse"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.reverse">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">reversed_axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># type: (Node, List[int], str) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Perform axis-reverse operation.</span>

<span class="sd">    :param node: The input node on which operation will be carried out.</span>
<span class="sd">    :param reversed_axes: The list of indices of axes to be reversed.</span>
<span class="sd">    :param name: The optional name of the output node.</span>
<span class="sd">    :return: The new node with reversed axes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Reverse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AxisSet</span><span class="p">(</span><span class="n">reversed_axes</span><span class="p">))</span></div>


<div class="viewcode-block" id="batch_norm"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.batch_norm">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">batch_norm</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span>             <span class="c1"># type: float</span>
               <span class="n">gamma</span><span class="p">,</span>           <span class="c1"># type: Node</span>
               <span class="n">beta</span><span class="p">,</span>            <span class="c1"># type: Node</span>
               <span class="n">data</span><span class="p">,</span>            <span class="c1"># type: Node</span>
               <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>       <span class="c1"># type: Node</span>
               <span class="n">variance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>   <span class="c1"># type: Node</span>
               <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>       <span class="c1"># type: str</span>
               <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return batch normalization node.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">variance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BatchNormTraining</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BatchNormInference</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span></div>


<div class="viewcode-block" id="lrn"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.lrn">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">lrn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>       <span class="c1"># type: Node</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>    <span class="c1"># type: float</span>
        <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>   <span class="c1"># type: float</span>
        <span class="n">bias</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>     <span class="c1"># type: float</span>
        <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>     <span class="c1"># type: int</span>
        <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: str</span>
        <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return a node which performs element-wise Local Response Normalization (LRN) operation.</span>

<span class="sd">    :param data: Input data.</span>
<span class="sd">    :param alpha: A scale factor (usually positive).</span>
<span class="sd">    :param beta: An exponent.</span>
<span class="sd">    :param bias: An offset (usually positive) to avoid dividing by 0.</span>
<span class="sd">    :param size: Width of the 1-D normalization window.</span>
<span class="sd">    :param name: An optional name of the output node.</span>
<span class="sd">    :return: The new node which performs LRN.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">LRN</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="argmax"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.argmax">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">argmax</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>     <span class="c1"># type: Node</span>
           <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>   <span class="c1"># type: int</span>
           <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return a node which performs ArgMax index reduction operation.</span>

<span class="sd">    :param data: Input data.</span>
<span class="sd">    :param axis: Reduction Axis.</span>
<span class="sd">    :return: The new node which performs ArgMax</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ArgMax</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span></div>


<div class="viewcode-block" id="argmin"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.argmin">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">argmin</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>    <span class="c1"># type: Node</span>
           <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># type: int</span>
           <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return a node which performs ArgMin index reduction operation.</span>

<span class="sd">    :param data: Input data.</span>
<span class="sd">    :param axis: Reduction Axis.</span>
<span class="sd">    :return: The new node which performs ArgMin</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ArgMin</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">get_element_type</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span></div>


<div class="viewcode-block" id="topk"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.topk">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">topk</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>       <span class="c1"># type: Node</span>
         <span class="n">k</span><span class="p">,</span>          <span class="c1"># type: int</span>
         <span class="n">kaxis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>   <span class="c1"># type: int</span>
         <span class="n">cmax</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># type: bool</span>
         <span class="p">):</span>
    <span class="c1"># type: (...) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return a node which performs TopK.</span>

<span class="sd">    :param data: Input data.</span>
<span class="sd">    :param kaxis: TopK Axis.</span>
<span class="sd">    :param k: K.</span>
<span class="sd">    :param cmax: Compute TopK largest (True) or smallest (False)</span>
<span class="sd">    :return: The new node which performs TopK (both indices and values)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TopK</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">kaxis</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">kaxis</span><span class="p">,</span>
                <span class="n">get_element_type</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                <span class="n">k</span><span class="p">,</span>
                <span class="n">cmax</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_output_element"><a class="viewcode-back" href="../../python_api/_autosummary/ngraph.html#ngraph.ops.get_output_element">[docs]</a><span class="nd">@nameable_op</span>
<span class="k">def</span> <span class="nf">get_output_element</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>  <span class="c1"># type: (Node, int) -&gt; Node</span>
    <span class="sd">&quot;&quot;&quot;Return the n-th element of the input tuple.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">GetOutputElement</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        <span class="crt-size">&copy; Copyright 2017-2020, Intel Corporation.</span> <br/><div class="brandnote"> Intel nGraph Library contains trademarks of Intel Corporation or its subsidiaries in the U.S. and/or other countries. * Other names and brands may be claimed as the property of others; see <a href="http://ngraph.nervanasys.com/docs/latest/branding-notice.html">branding notice</a> for more information.</class>
      Last updated on Jan 29, 2020.

    </p>
  </div>
<span class="pull-right"><span class="docbws">
  Documentation built with <a href="http://sphinx-doc.org/">Sphinx</a>. Find our code on <a href="https://www.github.com/NervanaSystems/">GitHub</a>.</span></span> 
</p>
</footer>

        </div>
      </div>

    </section>

  </div>

  

 
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>