

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Import a model &mdash; Documentation for the nGraph Library and Compiler Stack</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  
  
<!-- <link href="https://fonts.googleapis.com/css?family=Nunito:300,300i,400&display=swap&subset=latin-ext" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Nunito+Sans:300,400,600,700,800,900" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="Documentation for the nGraph Library and Compiler Stack" href="../../index.html"/>
        <link rel="up" title="Constructing Graphs" href="index.html"/>
        <link rel="next" title="Python API" href="../../python_api/index.html"/>
        <link rel="prev" title="Distribute training across multiple nGraph backends" href="distribute-train.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>


<body> 
  <div id="menu-float" class="menu-float">
    <a href="https://www.ngraph.ai" target="_blank"><i class="fa fa-home"></i></a>
    <a href="https://ngraph.nervanasys.com/docs/latest" title="Documentation Home"><i class="fa fa-book"></i></a>
    <a href="https://www.ngraph.ai/tutorials" title="Tutorials"><i class="fa fa-user-circle"></i></a>
    <a href="https://www.youtube.com/embed/C9S0nmNS8bQ" target="_blank"><i class="fa fa-video-camera"></i></a>
    <a href="https://ngraph.slack.com/" title="nGraph Slack Channel"><i class="fa fa-slack"></i></a>
    <a href="https://github.com/NervanaSystems/ngraph/blob/master/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
    <a href="https://www.github.com/NervanaSystems/ngraph"><img src="https://travis-ci.org/NervanaSystems/ngraph.svg?branch=master"></a></div></body>


<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html">
          

          
            
            <br/><img src="../../_static/logo.png" class="logo" />
	    nGraph Compiler Stack
          
          </a>

          
            
            
              <div class="version">
                0.29
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search nGraph Documentation" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

    <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="docvs">nGraph Compiler stack</span>
      v: 0.29
      <span></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Recent Versions<i class="fa fa-terminal"></i></dt>
        <dd><!-- Until our https://docs.ngraph.ai/ publishing is set up, we link to GitHub -->  
          <ul>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.27.1-rc.1">0.27.1</a></li> 
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.27.0-rc.1">0.27.0</a></li> 
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.26.0">0.26.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.25.1-rc.10">0.25.1</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.25.0">0.25.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.24.0">0.24.0</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.22.2-rc.0">0.22.2</a></li>
           <li><a href="https://github.com/NervanaSystems/ngraph/releases/tag/v0.22.1">0.22.1</a></li>
         </ul></dd>
      </dl>
      <dl>
        <dt>Links</dt>
          <dd>
           <a href="https://www.ngraph.ai/">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/NervanaSystems/ngraph/releases">All Releases</a>
          </dd>
      </dl>
    </div>
</div>


        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
            <span class="toctree-expand"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
</ul>
<p class="caption"><span class="caption-text">Framework Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/overview.html">Basic concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/tensorflow_connect.html">TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/onnx_integ.html">ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/paddle_integ.html">PaddlePaddle*</a></li>
</ul>
<p class="caption"><span class="caption-text">nGraph Core</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../buildlb.html">Build and Test</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Constructing Graphs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="execute.html">Execute a computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="operator.html">Build a graph with operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="update.html">Make a stateful computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="derive-for-training.html">Derive a trainable model</a></li>
<li class="toctree-l2"><a class="reference internal" href="distribute-train.html">Distribute training across multiple nGraph backends</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Import a model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/index.html">Using the Python API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../passes/passes.html">Compiler Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fusion/index.html">Pattern Matcher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ops/index.html">nGraph Core Ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../provenance/index.html">Provenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dynamic/index.html">Dynamic Shapes</a></li>
</ul>
<p class="caption"><span class="caption-text">Backend Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../backends/index.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends/cpp-api.html">Adding New Backends</a></li>
</ul>
<p class="caption"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/qat.html">Quantization-Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Validated Workloads</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frameworks/validated/list.html">Validated Workloads</a></li>
</ul>
<p class="caption"><span class="caption-text">Diagnostics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_core.html">Diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_tf.html">Debug TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_onnx.html">Debug ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/debug_paddle.html">Debug PaddlePaddle*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/viz_tools.html">General Visualization Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inspection/profiling.html">Performance testing with <code class="docutils literal notranslate"><span class="pre">nbench</span></code></a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../project/contribution-guide.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
</span>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">nGraph Compiler Stack</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
        <li><a href="index.html">Constructing Graphs</a> &raquo;</li>
      
    <li>Import a model</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="../../_sources/core/constructing-graphs/import.rst.txt" rel="nofollow"> View page source</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="import-a-model">
<h1>Import a model<a class="headerlink" href="#import-a-model" title="Permalink to this headline">¶</a></h1>
<p><a class="reference internal" href="#from-onnx"><span class="std std-ref">Importing a model from ONNX</span></a></p>
<p>nGraph APIs can be used to run inference on a model that has been <em>exported</em>
from a Deep Learning framework. An export produces a file with a serialized
model that can be loaded and passed to one of the nGraph backends.</p>
<div class="section" id="importing-a-model-from-onnx">
<span id="from-onnx"></span><h2>Importing a model from ONNX<a class="headerlink" href="#importing-a-model-from-onnx" title="Permalink to this headline">¶</a></h2>
<p>The most-widely supported <a class="reference internal" href="../../glossary.html#term-export"><span class="xref std std-term">export</span></a> format available today is <a class="reference external" href="http://onnx.ai">ONNX</a>.
Models that have been serialized to ONNX are easy to identify; they are
usually named <code class="docutils literal notranslate"><span class="pre">&lt;some_model&gt;.onnx</span></code> or <code class="docutils literal notranslate"><span class="pre">&lt;some_model&gt;.onnx.pb</span></code>. These
<a class="reference external" href="https://github.com/onnx/tutorials">tutorials from ONNX</a> describe how to turn trained models into an
<code class="docutils literal notranslate"><span class="pre">.onnx</span></code> export.</p>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p class="last">If you landed on this page and you already have an <code class="docutils literal notranslate"><span class="pre">.onnx</span></code> or
an <code class="docutils literal notranslate"><span class="pre">.onnx.pb</span></code> formatted file, you should be able to run the inference without
needing to dig into anything from the “Frameworks” sections. You will, however,
need to have completed the steps outlined in our <a class="reference internal" href="../../buildlb.html"><span class="doc">Build and Test</span></a> guide.</p>
</div>
<p>To demonstrate functionality, we’ll use an already-serialized CIFAR10 model
trained via ResNet20. Remember that this model has already been trained and
exported from a framework such as Caffe2, PyTorch or CNTK; we are simply going
to build an nGraph representation of the model, execute it, and produce some
outputs.</p>
</div>
<div class="section" id="installing-ngraph-onnx-with-ngraph-from-scratch">
<h2>Installing <code class="docutils literal notranslate"><span class="pre">ngraph_onnx</span></code> with nGraph from scratch<a class="headerlink" href="#installing-ngraph-onnx-with-ngraph-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>See the documentation on: <a class="reference external" href="https://github.com/NervanaSystems/ngraph-onnx/blob/master/BUILDING.md">building nGraph and nGraph-ONNX</a> for the latest
instructions.</p>
</div>
<div class="section" id="importing-a-serialized-model">
<span id="import-model"></span><h2>Importing a serialized model<a class="headerlink" href="#importing-a-serialized-model" title="Permalink to this headline">¶</a></h2>
<p>After building and installing <code class="docutils literal notranslate"><span class="pre">ngraph_onnx</span></code>, we can import a model that has
been serialized by ONNX, interact locally with the model by running
Python code, create and load objects, and run inference.</p>
<p>This section assumes that you have your own ONNX model. With this
example model from Microsoft*’s Deep Learning framework, <a class="reference external" href="https://www.microsoft.com/en-us/cognitive-toolkit/features/model-gallery/">CNTK</a>,
we can outline the procedure to show how to run ResNet on model
that has been trained on the CIFAR10 data set and serialized with
ONNX.</p>
<div class="section" id="optional-localize-your-export-to-the-virtual-environment">
<h3>(Optional) Localize your export to the virtual environment<a class="headerlink" href="#optional-localize-your-export-to-the-virtual-environment" title="Permalink to this headline">¶</a></h3>
<p>For this example, let’s say that our serialized file was output under our $HOME
directory, say at <code class="docutils literal notranslate"><span class="pre">~/onnx_conversions/trained_model.onnx</span></code>. To make loading this
file easier, you can run the example below from your Venv in that directory. If
you invoke your python interpreter in a different directory, you will need to
specify the relative path to the location of the <code class="docutils literal notranslate"><span class="pre">.onnx</span></code> file.</p>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p class="last">If you invoke your Python interpreter in directory other than
where you outputted your trained model, you will need to specify the
<strong>relative</strong> path to the location of the <code class="docutils literal notranslate"><span class="pre">.onnx</span></code> file.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">(onnx) $</span> <span class="nb">cd</span> ~/onnx_conversions
<span class="gp">(onnx) $</span> python3
</pre></div>
</div>
</div>
<div class="section" id="enable-onnx-and-load-an-onnx-file-from-disk">
<h3>Enable ONNX and load an ONNX file from disk<a class="headerlink" href="#enable-onnx-and-load-an-onnx-file-from-disk" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>

<span class="n">onnx_protobuf</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/model/cntk_ResNet20_CIFAR10/model.onnx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="convert-an-onnx-model-to-an-ngraph-model">
<h3>Convert an ONNX model to an ngraph model<a class="headerlink" href="#convert-an-onnx-model-to-an-ngraph-model" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ngraph_onnx.onnx_importer.importer</span> <span class="kn">import</span> <span class="n">import_onnx_model</span>
<span class="n">ng_model</span> <span class="o">=</span> <span class="n">import_onnx_model</span><span class="p">(</span><span class="n">onnx_protobuf</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>The importer returns a list of ngraph models for every ONNX graph
output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ng_models</span><span class="p">)</span>
<span class="p">[{</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Plus5475_Output_0&#39;</span><span class="p">,</span>
    <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">Add</span><span class="p">:</span> <span class="s1">&#39;Add_1972&#39;</span> <span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">&lt;</span><span class="n">Parameter</span><span class="p">:</span> <span class="s1">&#39;Parameter_1104&#39;</span> <span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="nb">float</span><span class="p">)</span><span class="o">&gt;</span><span class="p">]</span>
 <span class="p">}]</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">output</span></code> field contains the ngraph node corrsponding to the output node
in the imported ONNX computational graph. The <code class="docutils literal notranslate"><span class="pre">inputs</span></code> list contains all
input parameters for the computation which generates the output.</p>
</div>
<div class="section" id="using-ngraph-api-create-a-callable-computation-object">
<h3>Using ngraph_api, create a callable computation object<a class="headerlink" href="#using-ngraph-api-create-a-callable-computation-object" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ngraph</span> <span class="kn">as</span> <span class="nn">ng</span>
<span class="n">runtime</span> <span class="o">=</span> <span class="n">ng</span><span class="o">.</span><span class="n">runtime</span><span class="p">(</span><span class="n">backend_name</span><span class="o">=</span><span class="s1">&#39;CPU&#39;</span><span class="p">)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">computation</span><span class="p">(</span><span class="n">ng_model</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span> <span class="o">*</span><span class="n">ng_model</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="load-or-create-an-image">
<h3>Load or create an image<a class="headerlink" href="#load-or-create-an-image" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">picture</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="run-resnet-inference-on-picture">
<h3>Run ResNet inference on picture<a class="headerlink" href="#run-resnet-inference-on-picture" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">resnet</span><span class="p">(</span><span class="n">picture</span><span class="p">)</span>

</pre></div>
</div>
</div>
</div>
<div class="section" id="put-it-all-together">
<h2>Put it all together<a class="headerlink" href="#put-it-all-together" title="Permalink to this headline">¶</a></h2>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">“Demo sample code to run inference with nGraph”</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>

<span class="n">onnx_protobuf</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/path/to/model/cntk_ResNet20_CIFAR10/model.onnx&#39;</span><span class="p">)</span>

<span class="c1"># Convert a serialized ONNX model to an ngraph model</span>
<span class="kn">from</span> <span class="nn">ngraph_onnx.onnx_importer.importer</span> <span class="kn">import</span> <span class="n">import_onnx_model</span>
<span class="n">ng_model</span> <span class="o">=</span> <span class="n">import_onnx_model</span><span class="p">(</span><span class="n">onnx_protobuf</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="c1"># Using an ngraph runtime (CPU backend), create a callable computation</span>
<span class="kn">import</span> <span class="nn">ngraph</span> <span class="kn">as</span> <span class="nn">ng</span>
<span class="n">runtime</span> <span class="o">=</span> <span class="n">ng</span><span class="o">.</span><span class="n">runtime</span><span class="p">(</span><span class="n">backend_name</span><span class="o">=</span><span class="s1">&#39;CPU&#39;</span><span class="p">)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">computation</span><span class="p">(</span><span class="n">ng_model</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span> <span class="o">*</span><span class="n">ng_model</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">])</span>

<span class="c1"># Load or create an image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">picture</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>

<span class="c1"># Run ResNet inference on picture</span>
<span class="n">resnet</span><span class="p">(</span><span class="n">picture</span><span class="p">)</span>

</pre></div>
</div>
</div>
<p>Outputs will vary greatly, depending on your model; for
demonstration purposes, the code will look something like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.312082</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.6729496</span><span class="p">,</span>  <span class="mf">4.2079577</span><span class="p">,</span>  <span class="mf">1.4012241</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.5463796</span><span class="p">,</span>
      <span class="mf">2.3433776</span><span class="p">,</span>  <span class="mf">1.7799224</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6155214</span><span class="p">,</span>  <span class="mf">0.0777044</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2944093</span><span class="p">]],</span>
   <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../python_api/index.html" class="btn btn-neutral float-right" title="Python API" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="distribute-train.html" class="btn btn-neutral" title="Distribute training across multiple nGraph backends" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        <span class="crt-size">&copy; Copyright 2017-2020, Intel Corporation.</span> <br/><div class="brandnote"> Intel nGraph Library contains trademarks of Intel Corporation or its subsidiaries in the U.S. and/or other countries. * Other names and brands may be claimed as the property of others; see <a href="http://ngraph.nervanasys.com/docs/latest/branding-notice.html">branding notice</a> for more information.</class>
      Last updated on Jan 29, 2020.

    </p>
  </div>
<span class="pull-right"><span class="docbws">
  Documentation built with <a href="http://sphinx-doc.org/">Sphinx</a>. Find our code on <a href="https://www.github.com/NervanaSystems/">GitHub</a>.</span></span> 
</p>
</footer>

        </div>
      </div>

    </section>

  </div>

  

 
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>